{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GwFa7tf2nfob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b7f9781-56fb-4ac1-def4-41b870d5aff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras import  models, layers\n",
        "\n",
        "IMAGE_SIZE = 256\n",
        "BATCH_SIZE = 32\n",
        "CHANNELS = 3\n",
        "EPOCHS = 50\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        \"/content/drive/MyDrive/Datastets/Splitted/train\",\n",
        "        shuffle = True,\n",
        "        image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
        "        batch_size = BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        \"/content/drive/MyDrive/Datastets/Splitted/val\",\n",
        "        shuffle = True,\n",
        "        image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
        "        batch_size = BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        \"/content/drive/MyDrive/Datastets/Splitted/test\",\n",
        "        shuffle = True,\n",
        "        image_size = (IMAGE_SIZE, IMAGE_SIZE),\n",
        "        batch_size = BATCH_SIZE\n",
        ")\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.cache().shuffle(1000).prefetch(buffer_size = tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "1qejMFH4pbyT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ca7d62c-74c5-4df5-e46f-b7fea48dff16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 32083 files belonging to 33 classes.\n",
            "Found 4002 files belonging to 33 classes.\n",
            "Found 4000 files belonging to 33 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG16\n"
      ],
      "metadata": {
        "id": "7IZbRjKmpSjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_VGG16(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    Compiles a VGG16 model with pre-trained layers.\n",
        "    \n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. If set to 0, all\n",
        "                     pre-trained layers will freeze during training\n",
        "    \"\"\"\n",
        "\n",
        "    model_base = tf.keras.applications.VGG16(include_top=False, # exclude the model's fully-connected layers\n",
        "                     weights='imagenet', # weights pre-trained using the Imagenet\n",
        "                     input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    if fine_tune > 0:\n",
        "        for layer in model_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in model_base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Create a new 'top' of the model (i.e. 3 fully-connected layers).\n",
        "    inputs = tf.keras.Input(shape=(input_shape))\n",
        "    top_model = tf.keras.applications.vgg16.preprocess_input(inputs)\n",
        "    top_model = model_base(top_model)\n",
        "    top_model = layers.Flatten(name=\"flatten\")(top_model)\n",
        "    top_model = layers.Dense(4096, activation='relu')(top_model)\n",
        "    top_model = layers.Dense(4096, activation='relu')(top_model)\n",
        "    top_model = layers.Dense(4096, activation='relu')(top_model)\n",
        "    output_layer = layers.Dense(n_classes, activation='softmax')(top_model)\n",
        "    \n",
        "    # Create a final output.\n",
        "    model = models.Model(inputs=inputs, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "VGG16_model = create_VGG16((IMAGE_SIZE, IMAGE_SIZE, 3), 33, \n",
        "                           optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=10**(-7)),\n",
        "                           fine_tune=2)\n",
        "\n",
        "history_logger = CSVLogger('VGG16_model_Adam.csv', separator=\",\", append=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "\n",
        "history = VGG16_model.fit(train_ds,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[history_logger, earlyStopping])\n",
        "\n",
        "VGG16_model.save('VGG16_model_Adam.keras')"
      ],
      "metadata": {
        "id": "TDCHENTgpYmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52fb1f7-236b-4817-8f39-46fa96c556a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50"
      ],
      "metadata": {
        "id": "Q7fJBcl4tHgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_ResNet50(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    Compiles a ResNet50 model with pre-trained layers.\n",
        "    \n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. If set to 0, all\n",
        "                     pre-trained layers will freeze during training\n",
        "    \"\"\"\n",
        "\n",
        "    model_base = tf.keras.applications.ResNet50(include_top=False, # exclude the model's fully-connected layers\n",
        "                                             weights='imagenet', # weights pre-trained using the Imagenet\n",
        "                                             input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    if fine_tune > 0:\n",
        "        for layer in model_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in model_base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Preprocessing layers\n",
        "    resize_and_rescale = tf.keras.Sequential([\n",
        "                                  layers.experimental.preprocessing.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n",
        "                                  layers.experimental.preprocessing.Rescaling(1.0/255)])\n",
        "\n",
        "    # Create a new 'top' of the model.\n",
        "    inputs = tf.keras.Input(shape=(input_shape))\n",
        "    top_model = resize_and_rescale(inputs)\n",
        "    top_model = model_base(top_model)\n",
        "    top_model = layers.Flatten(name=\"flatten\")(top_model)\n",
        "    output_layer = layers.Dense(n_classes, activation='softmax')(top_model)\n",
        "    \n",
        "    # Create a final output.\n",
        "    model = models.Model(inputs=inputs, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "ResNet50_model = create_ResNet50((IMAGE_SIZE, IMAGE_SIZE, 3), 33, \n",
        "                                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=10**(-7)),\n",
        "                                 fine_tune=4)\n",
        "\n",
        "history_logger = CSVLogger('ResNet50_model_Adam.csv', separator=\",\", append=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "\n",
        "history = ResNet50_model.fit(train_ds,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[history_logger, earlyStopping])\n",
        "\n",
        "ResNet50_model.save('ResNet50_model_Adam.keras')"
      ],
      "metadata": {
        "id": "B0Qod58JtG6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05255c64-933a-428b-e857-7efbadb72778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inception-V3"
      ],
      "metadata": {
        "id": "ueqa3haByGha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_InceptionV3(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    Compiles a Inception-V3 model with pre-trained layers.\n",
        "    \n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. If set to 0, all\n",
        "                     pre-trained layers will freeze during training\n",
        "    \"\"\"\n",
        "\n",
        "    model_base = tf.keras.applications.InceptionV3(include_top=False, # exclude the model's fully-connected layers\n",
        "                                             weights='imagenet', # weights pre-trained using the Imagenet\n",
        "                                             input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    if fine_tune > 0:\n",
        "        for layer in model_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in model_base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Create a new 'top' of the model.\n",
        "    inputs = tf.keras.Input(shape=(input_shape))\n",
        "    top_model = tf.keras.applications.inception_v3.preprocess_input(inputs)\n",
        "    top_model = model_base(top_model)\n",
        "    top_model = layers.Flatten(name=\"flatten\")(top_model)\n",
        "    output_layer = layers.Dense(n_classes, activation='softmax')(top_model)\n",
        "    \n",
        "    # Create a final output.\n",
        "    model = models.Model(inputs=inputs, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "InceptionV3_model = create_InceptionV3((IMAGE_SIZE, IMAGE_SIZE, 3), 33, \n",
        "                                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=10**(-7)),\n",
        "                                 fine_tune=1)\n",
        "\n",
        "history_logger = CSVLogger('InceptionV3_model_Adam.csv', separator=\",\", append=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "\n",
        "history = InceptionV3_model.fit(train_ds,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[history_logger, earlyStopping])\n",
        "\n",
        "InceptionV3_model.save('InceptionV3_model_Adam.keras')"
      ],
      "metadata": {
        "id": "wqY3uY83w1KG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774bbdb3-361b-4db6-f0c1-64c27601a36f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xception"
      ],
      "metadata": {
        "id": "nAy6l0jazsTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_Xception(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    Compiles a Xception model with pre-trained layers.\n",
        "    \n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. If set to 0, all\n",
        "                     pre-trained layers will freeze during training\n",
        "    \"\"\"\n",
        "\n",
        "    model_base = tf.keras.applications.Xception(include_top=False, # exclude the model's fully-connected layers\n",
        "                                             weights='imagenet', # weights pre-trained using the Imagenet\n",
        "                                             input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    if fine_tune > 0:\n",
        "        for layer in model_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in model_base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Create a new 'top' of the model.\n",
        "    inputs = tf.keras.Input(shape=(input_shape))\n",
        "    top_model = tf.keras.applications.xception.preprocess_input(inputs)\n",
        "    top_model = model_base(top_model)\n",
        "    top_model = layers.Flatten(name=\"flatten\")(top_model)\n",
        "    output_layer = layers.Dense(n_classes, activation='softmax')(top_model)\n",
        "    \n",
        "    # Create a final output.\n",
        "    model = models.Model(inputs=inputs, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "Xception_model = create_Xception((IMAGE_SIZE, IMAGE_SIZE, 3), 33, \n",
        "                                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=10**(-7)),\n",
        "                                 fine_tune=2)\n",
        "\n",
        "history_logger = CSVLogger('Xception_model_Adam.csv', separator=\",\", append=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "\n",
        "history = Xception_model.fit(train_ds,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[history_logger, earlyStopping])\n",
        "\n",
        "Xception_model.save('Xception_model_Adam.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc_zy_ywzfTL",
        "outputId": "0cafda9c-6929-4baa-fbe5-c56d1ace2eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 1s 0us/step\n",
            "Epoch 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DenseNet201"
      ],
      "metadata": {
        "id": "yQB7aFOf1V_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_DenseNet201(input_shape, n_classes, optimizer, fine_tune=0):\n",
        "    \"\"\"\n",
        "    Compiles a DenseNet201 model with pre-trained layers.\n",
        "    \n",
        "    input_shape: tuple - the shape of input images (width, height, channels)\n",
        "    n_classes: int - number of classes for the output layer\n",
        "    optimizer: string - instantiated optimizer to use for training.\n",
        "    fine_tune: int - The number of pre-trained layers to unfreeze. If set to 0, all\n",
        "                     pre-trained layers will freeze during training\n",
        "    \"\"\"\n",
        "\n",
        "    model_base = tf.keras.applications.DenseNet201(include_top=False, # exclude the model's fully-connected layers\n",
        "                                             weights='imagenet', # weights pre-trained using the Imagenet\n",
        "                                             input_shape=input_shape)\n",
        "    \n",
        "    # Defines how many layers to freeze during training.\n",
        "    if fine_tune > 0:\n",
        "        for layer in model_base.layers[:-fine_tune]:\n",
        "            layer.trainable = False\n",
        "    else:\n",
        "        for layer in model_base.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # Create a new 'top' of the model.\n",
        "    inputs = tf.keras.Input(shape=(input_shape))\n",
        "    top_model = tf.keras.applications.densenet.preprocess_input(inputs)\n",
        "    top_model = model_base(top_model)\n",
        "    top_model = layers.Flatten(name=\"flatten\")(top_model)\n",
        "    top_model = layers.Dense(256, activation='relu')(top_model)\n",
        "    output_layer = layers.Dense(n_classes, activation='softmax')(top_model)\n",
        "    \n",
        "    # Create a final output.\n",
        "    model = models.Model(inputs=inputs, outputs=output_layer)\n",
        "\n",
        "    # Compiles the model for training.\n",
        "    model.compile(optimizer=optimizer, \n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "DenseNet201_model = create_DenseNet201((IMAGE_SIZE, IMAGE_SIZE, 3), 33, \n",
        "                                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=10**(-7)),\n",
        "                                 fine_tune=3)\n",
        "\n",
        "history_logger = CSVLogger('DenseNet201_model_Adam.csv', separator=\",\", append=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "\n",
        "history = DenseNet201_model.fit(train_ds,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks=[history_logger, earlyStopping])\n",
        "\n",
        "DenseNet201_model.save('DenseNet201_model_Adam.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlLhz0c21KQj",
        "outputId": "b545ad0d-6218-4385-978a-fc0488ce8aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kpwZ0H5X2neE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}